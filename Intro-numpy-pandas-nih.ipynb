{
 "metadata": {
  "name": "",
  "signature": "sha256:caf7fff14b92233afae6b316419630eced1acc6156fc98e0cb4a5a960539f0c9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Introduction to Numpy & Pandas\n",
      "\n",
      "## R. Burke Squires\n",
      "\n",
      "\n",
      "\n",
      "[Numpy](http://numpy.scipy.org/) is the fundamental library for scientific computing in Python. It contains list like objects that work like arrays, matrices, and data tables. This is how scientists typically expect data to behave. Numpy also provides linear algebra, Fourier transforms, random number generation, and tools for integrating C/C++ and Fortran code.\n",
      "\n",
      "[Matplotlib](http://matplotlib.org/) is the reigning library for 2D (with budding support for 3D) scientific plotting in Python. It produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms.  Between Numpy and Matplotlib, much of MATLAB's functionality can be replaced with Python.\n",
      "\n",
      "If you primarily want to work with tables of data, [Pandas](pandas), which depends on Numpy, is probably the module that you want to start with.\n",
      "\n",
      "Source: Software Carpentry, http://software-carpentry.org"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Why Numpy?\n",
      "\n",
      "Python was never designed originally for scientific computing, and contains many high-level abstractions necessary to enable its enormously flexible object-oriented interface.  In Python, storing most integers requires more than just 4-8 bytes.  It also requires at least a couple pointers per-integer.  Performing a calculation on two numbers requires one or two bytecode operations, each of which can take dozens of CPU instructions for each pass through the Python eval loop.  And when it comes to looping and index operations of Python lists the situation is even more dire.\n",
      "\n",
      "### A basic example\n",
      "\n",
      "`Z = A + B * C`\n",
      "\n",
      "In pure Python:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create 3 lists of a million ints\n",
      "A = range(1000000)\n",
      "B = range(1000000)\n",
      "C = range(1000000)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Time doing the operation with a for loop\n",
      "import time\n",
      "\n",
      "start_time = time.time()\n",
      "\n",
      "Z = []\n",
      "for idx in xrange(len(A)):\n",
      "    Z.append(A[idx] + B[idx] * C[idx])\n",
      "    \n",
      "print 'Took', time.time() - start_time, 'seconds'\n",
      "    \n",
      "# print Z  # DON'T DO THIS!  It will print all 10000 array items"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Using Numpy:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create 3 Numpy arrays with a million ints\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "A = np.arange(1000000)\n",
      "B = np.arange(1000000)\n",
      "C = np.arange(1000000)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Time the operation with Numpy\n",
      "start_time = time.time()\n",
      "\n",
      "Z = A + B * C\n",
      "\n",
      "print 'Took', time.time() - start_time, 'seconds'"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Numpy is ', 0.398498058319 / 0.0146481990814 , 'times faster'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print the result\n",
      "Z = A + B * C\n",
      "print Z"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to just *looking* simpler, the Numpy version is significantly faster. The for loop disappears completely and is replaced by vectorized array operations."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Memory Usage\n",
      "3 x 1000000 lists of Python ints: ~96 MB\n",
      "\n",
      "3 x 1000000 Numpy arrays of 64-bit ints: ~32 MB"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Numpy and Matplotlib"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import numpy as np\n",
      "\n",
      "ax = subplot(111)\n",
      "x = np.arange(0.0, 5.0, 0.01)\n",
      "y = np.cos(x * np.pi)\n",
      "lines, = plot(x, y, lw=3)\n",
      "ylim(-1.5, 1.5)\n",
      "show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unlike Python lists, __NumPy arrays are homogeneous: all values must have exactly the same type.__ This allows values to be packed together, which saves memory and is much faster to process.\n",
      "\n",
      "If we give NumPy initial values of different types, it finds the most general type and stores all the values in the array using that type. For example, if we construct an array from an integer and a float, the array's values are both floats.\n",
      "\n",
      "__Note:__ Axis 0 and 1 are shown below."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/img/python-operations-across-axes.svg\" alt=\"Operations Across Axes\" />"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# An Introduction to Pandas\n",
      "\n",
      "** Presentation originally developed by Michael Hansen, modified slightly by Jeff Shelton **\n",
      "\n",
      "**pandas** is a Python package providing fast, flexible, and expressive data structures designed to work with *relational* or *labeled* data both. It is a fundamental high-level building block for doing practical, real world data analysis in Python. \n",
      "\n",
      "pandas is well suited for:\n",
      "\n",
      "- Tabular data with heterogeneously-typed columns, as in an SQL table or Excel spreadsheet\n",
      "- Ordered and unordered (not necessarily fixed-frequency) time series data.\n",
      "- Arbitrary matrix data (homogeneously typed or heterogeneous) with row and column labels\n",
      "- Any other form of observational / statistical data sets. The data actually need not be labeled at all to be placed into a pandas data structure\n",
      "\n",
      "\n",
      "Key features:\n",
      "    \n",
      "- Easy handling of **missing data**\n",
      "- **Size mutability**: columns can be inserted and deleted from DataFrame and higher dimensional objects\n",
      "- Automatic and explicit **data alignment**: objects can be explicitly aligned to a set of labels, or the data can be aligned automatically\n",
      "- Powerful, flexible **group by functionality** to perform split-apply-combine operations on data sets\n",
      "- Intelligent label-based **slicing, fancy indexing, and subsetting** of large data sets\n",
      "- Intuitive **merging and joining** data sets\n",
      "- Flexible **reshaping and pivoting** of data sets\n",
      "- **Hierarchical labeling** of axes\n",
      "- Robust **IO tools** for loading data from flat files, Excel files, databases, and HDF5\n",
      "- **Time series functionality**: date range generation and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging, etc."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When dealing with numeric matrices and vectors in Python, [NumPy](http://www.numpy.org/) makes life a lot easier.\n",
      "For more complex data, however, it leaves a lot to be desired.\n",
      "If you're used to working with [data frames in R](http://www.r-tutor.com/r-introduction/data-frame), doing data analysis directly with NumPy feels like a step back.\n",
      "\n",
      "Fortunately, some nice folks have written the [Python Data Analysis Library](http://pandas.pydata.org/) (a.k.a. pandas).\n",
      "Pandas provides an R-like `DataFrame`, produces high quality plots with [matplotlib](http://matplotlib.org/), and integrates nicely with other libraries that expect NumPy arrays.\n",
      "\n",
      "In this tutorial, we'll go through the basics of pandas using a year's worth of weather data from [Weather Underground](http://www.wunderground.com/).\n",
      "Pandas has a **lot** of functionality, so we'll only be able to cover a small fraction of what you can do.\n",
      "Check out the (very readable) [pandas docs](http://pandas.pydata.org/pandas-docs/stable/) if you want to learn more."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "HTML(\"<iframe src=http://pandas.pydata.org width=800 height=350></iframe>\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Getting Started"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK, let's get started by importing the pandas library."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import pandas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, let's read in [our data](data/weather_year.csv).\n",
      "Because it's in a CSV file, we can use pandas' `read_csv` function to pull it directly into a [DataFrame](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "data = pandas.read_csv(\"data/weather_year.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can get a summary of the DataFrame by asking for some information:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This gives us a lot of insight. First, we can see that there are 366 rows (entries) -- a year and a day's worth of weather. Each column is printed along with however many \"non-null\" values are present.\n",
      "We'll talk more about [null (or missing) values in pandas](http://pandas.pydata.org/pandas-docs/stable/missing_data.html) later, but for now we can note that only the \"Max Gust SpeedMPH\" and \"Events\" columns have fewer than 366 non-null values.\n",
      "Lastly, the data types (dtypes) of the columns are printed at the very bottom. We can see that there are 4 `float64`, 16 `int64`, and 3 `object` columns."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using `len` on a DataFrame will give you the number of rows. You can get the column names using the `columns` property."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Columns can be accessed in two ways. The first is using the DataFrame like a dictionary with string keys:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[\"EDT\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can get multiple columns out at the same time by passing in a list of strings."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[[\"EDT\", \"Mean TemperatureF\"]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The second way to access columns is using the dot syntax. This only works if your column name could also be a Python variable name (i.e., no spaces), and if it doesn't collide with another DataFrame property or function name (e.g., count, sum)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.EDT"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll be mostly using the dot syntax here because you can auto-complete the names in IPython. The first pandas function we'll learn about is `head()`. This gives us the first 5 items in a column (or the first 5 rows in the DataFrame)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.EDT.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Passing in a number `n` gives us the first `n` items in the column. There is also a corresponding `tail()` method that gives the *last* `n` items or rows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.EDT.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This also works with the dictionary syntax."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[\"Mean TemperatureF\"].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 1:\n",
      "\n",
      "How would we get the second to last date (EDT) in the dataset?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "data.EDT[364]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If the data in the column is numeric, you can use `describe()` to get some stats on it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[\"Mean TemperatureF\"].describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Fun with Columns"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The column names in `data` are a little unwieldy, so we're going to rename them. This is as easy as assigning a new list of column names to the `columns` property of the DataFrame."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "data.columns = [\"date\", \"max_temp\", \"mean_temp\", \"min_temp\", \"max_dew\",\n",
      "                \"mean_dew\", \"min_dew\", \"max_humidity\", \"mean_humidity\",\n",
      "                \"min_humidity\", \"max_pressure\", \"mean_pressure\",\n",
      "                \"min_pressure\", \"max_visibilty\", \"mean_visibility\",\n",
      "                \"min_visibility\", \"max_wind\", \"mean_wind\", \"min_wind\",\n",
      "                \"precipitation\", \"cloud_cover\", \"events\", \"wind_dir\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These should be in the same order as the original columns. Let's take another look at our DataFrame summary."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now our columns can all be accessed using the dot syntax!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.mean_temp.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are lots useful methods on columns, such as `std()` to get the standard deviation. Most of pandas' methods will happily ignore missing values like `NaN`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.mean_temp.std()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some methods, like `plot()` and `hist()` produce plots using [matplotlib](http://matplotlib.org/).\n",
      "\n",
      "To make plots using Matplotlib, you must first enable IPython's matplotlib mode. To do this, run the `%matplotlib inline` magic command to enable plotting in the current Notebook. \\[If that doesn't work (because you have an older version of IPython), try `%pylab inline`. You may also have to restart the IPython kernel.\\]\n",
      "\n",
      "We'll go over plotting in more detail later."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "data.mean_temp.hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you want to add labels and save the plot as a `png` file that is sized 800 pixels by 600 pixels:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ax = data.mean_temp.hist()   # get plot axes object\n",
      "ax.set_xlabel('Daily Mean Temperature (F)')\n",
      "ax.set_ylabel('# of Occurances')\n",
      "ax.set_title('Mean Temperature Histogram')\n",
      "\n",
      "fig = ax.get_figure()        # get plot figure object\n",
      "fig.set_size_inches(8,6)     # set plot size\n",
      "fig.savefig('MeanTempHistogram.png', dpi=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By the way, many of the column-specific methods also work on the entire DataFrame. Instead of a single number, you'll get a result for each column."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.std()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 2:\n",
      "\n",
      "What is the range of temperatures in the dataset?\n",
      "\n",
      "*Hint: columns have `max()` and `min()` methods.*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.max_temp.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Bulk Operations with `apply()`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Methods like `sum()` and `std()` work on entire columns. We can run our own functions across all values in a column (or row) using `apply()`.\n",
      "\n",
      "To give you an idea of how this works, let's consider the \"date\" column in our DataFrame (formally \"EDT\")."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.date.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use the `values` property of the column to get a list of values for the column. Inspecting the first value reveals that these are strings with a particular format."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_date = data.date.values[0]\n",
      "first_date"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `strptime` function from the `datetime` module will make quick work of this date string. There are many [more shortcuts available](http://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior) for `strptime`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import the datetime class from the datetime module\n",
      "from datetime import datetime\n",
      "\n",
      "# Convert date string to datetime object\n",
      "datetime.strptime(first_date, \"%Y-%m-%d\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the `apply()` method, which takes a function (**without** the parentheses), we can apply `strptime` to each value in the column. We'll overwrite the string date values with their Python `datetime` equivalents."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define a function to convert strings to dates\n",
      "def string_to_date(date_string):\n",
      "    return datetime.strptime(date_string, \"%Y-%m-%d\")\n",
      "\n",
      "# Run the function on every date string and overwrite the column\n",
      "data.date = data.date.apply(string_to_date)\n",
      "data.date.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's go one step futher. Each row in our DataFrame represents the weather from a single day. Each row in a DataFrame is associated with an *index*, which is a label that uniquely identifies a row.\n",
      "\n",
      "Our row indices up to now have been auto-generated by pandas, and are simply integers from 0 to 365. If we use dates instead of integers for our index, we will get some extra benefits from pandas when plotting later on. Overwriting the index is as easy as assigning to the `index` property of the DataFrame."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.index = data.date\n",
      "data.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can quickly look up a row by its date with the `loc[]` property \\[[see docs](http://pandas.pydata.org/pandas-docs/stable/indexing.html)], which locates records by label."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.loc[datetime(2012, 8, 19)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also access a row (or range of rows) with the `iloc[]` property, which locates records by integer index."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.max_temp.iloc[7:15]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With all of the dates in the index now, we no longer need the \"date\" column. Let's drop it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = data.drop(\"date\", axis=1)\n",
      "data.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that we need to pass in `axis=1` in order to drop a column. For more details, check out the [documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html) for `drop`. The index values can now be accessed as `data.index.values`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 3:\n",
      "\n",
      "Print out the cloud cover for each day in May.\n",
      "\n",
      "*Hint: you can make datetime objects with the `datetime(year, month, day)` function*\n",
      "\n",
      "*For extra credit, try using the `date_range()` function; see [pandas.date_range](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.date_range.html)*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datetime(2012, 5, 1)  # May 1st of 2012\n",
      "print type(data.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data.cloud_cover.loc[datetime(2012, 5, 1)]\n",
      "rng = pandas.date_range('5/1/2012','5/31/2012',freq='D') \n",
      "data.cloud_cover.loc[rng]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Handing Missing Values"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pandas considers values like `NaN` and `None` to represent missing data. The `count()` function [[see docs](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.count.html)] can be used to tell whether values are missing. We use the parameter `axis=0` to indicate that we want to perform the count by rows, rather than columns."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.count(axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is pretty obvious that there are a lot of `NaN` entrys for the `events` column; 204 to be exact. Let's take a look at a few values from the `events` column:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.events.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This isn't exactly what we want. One option is to drop all rows in the DataFrame with missing \"events\" values using the `dropna()` function \\[[see docs](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html)]."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.dropna(subset=[\"events\"]).info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that this didn't affect `data`; we're just looking at a copy.\n",
      "\n",
      "Instead of dropping rows with missing values, let's fill them with empty strings (you'll see why in a moment). This is easily done with the `fillna()` function. We'll go ahead and overwrite the \"events\" column with empty string missing values instead of `NaN`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.events = data.events.fillna(\"\")\n",
      "data.events.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we repeat the `count` function for the `events` column:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.events.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As desired, there are no longer any empty entries in the `events` column. Why did we not need the `axis=0` parameter this time?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Iteratively Accessing Rows"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can iterate over each row in the DataFrame with `iterrows()`. Note that this function returns **both** the index and the row. Also, you must access columns in the row you get back from `iterrows()` with the dictionary syntax."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_rain = 0\n",
      "for idx, row in data.iterrows():\n",
      "    if \"Rain\" in row[\"events\"]:\n",
      "        num_rain += 1\n",
      "\n",
      "\"Days with rain: {0}\".format(num_rain)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 4:\n",
      "\n",
      "Was there any November rain?\n",
      "\n",
      "*Hint*: check out the `strftime()` function on `datetime` objects and the [documentation](http://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = datetime(2012, 1, 1)\n",
      "d.strftime(\"%B\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Filtering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Most of your time using pandas will likely be devoted to selecting rows of interest from a DataFrame. In addition to strings, the dictionary syntax accepts requests like:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freezing_days = data[data.max_temp <= 32]\n",
      "freezing_days.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We get back another DataFrame with fewer rows (21 in this case). This DataFrame can be filtered down even more by adding a constrain that the temperature be greater than 20 degrees, in addition to being below freezing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cold_days = freezing_days[freezing_days.min_temp >= 20]\n",
      "cold_days.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To see the high and low temperatures for the selected days:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cold_days[[\"max_temp\",\"min_temp\"]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using boolean operations, we could have chosen to apply both filters to the original DataFrame at the same time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[(data.max_temp <= 32) & (data.min_temp >= 20)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It's important to understand what's really going on underneath with filtering. Let's look at what kind of object we actually get back when creating a filter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp_max = data.max_temp <= 32\n",
      "type(temp_max)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a pandas `Series` object, which is the one-dimensional equivalent of a DataFrame. Because our DataFrame uses datetime objects for the index, we have a specialized `TimeSeries` object.\n",
      "\n",
      "What's inside the filter?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp_max"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our filter is nothing more than a `Series` with a *boolean value for every item in the index*. When we \"run the filter\" as so:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[temp_max].info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "pandas lines up the rows of the DataFrame and the filter using the index, and then keeps the rows with a `True` filter value. That's it.\n",
      "\n",
      "Let's create another filter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp_min = data.min_temp >= 20\n",
      "temp_min"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can see what the boolean operations are doing. Something like `&` (**not** `and`)..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp_min & temp_max"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "...is just lining up the two filters using the index, performing a boolean AND operation, and returning the result as another `Series`.\n",
      "\n",
      "We can do other boolean operations too, like OR:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp_min | temp_max"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because the result is just another `Series`, we have all of the regular pandas functions at our disposal. The `any()` function returns `True` if any value in the `Series` is `True`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp_both = temp_min & temp_max\n",
      "temp_both.any()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sometimes filters aren't so intuitive. This (sadly) doesn't work:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "try:\n",
      "    data[\"Rain\" in data.events]\n",
      "except:\n",
      "    pass # \"KeyError: no item named False\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can wrap it up in an `apply()` call fairly easily, though:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[data.events.apply(lambda e: \"Rain\" in e)].info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 5:\n",
      "\n",
      "Before starting the exercise, let's convert the precipitation column in the dataset to floating point numbers. It's currently full of strings because of the \"T\" value, which stands for \"trace amount of precipitation.\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.precipitation.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll replace \"T\" with a very small number, and convert the rest of the strings to floats:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert precipitation to floating point number\n",
      "# \"T\" means \"trace of precipitation\"\n",
      "def precipitation_to_float(precip_str):\n",
      "    if precip_str == \"T\":\n",
      "        return 1e-10  # Very small value\n",
      "    return float(precip_str)\n",
      "\n",
      "data.precipitation = data.precipitation.apply(precipitation_to_float)\n",
      "data.precipitation.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now on to the exercise.\n",
      "\n",
      "What was the coldest and hottest it ever got when there was no cloud cover and no precipitation?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Grouping"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Besides `apply()`, another great DataFrame function is `groupby()`.\n",
      "It will group a DataFrame by one or more columns, and let you iterate through each group.\n",
      "\n",
      "As an example, let's group our DataFrame by the \"cloud_cover\" column (a value ranging from 0 to 8)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cover_temps = {}\n",
      "for cover, cover_data in data.groupby(\"cloud_cover\"):\n",
      "    cover_temps[cover] = cover_data.mean_temp.mean()  # The mean mean temp!\n",
      "cover_temps"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When you iterate through the result of `groupby()`, you will get a tuple.\n",
      "The first item is the column value, and the second item is a filtered DataFrame (where the column equals the first tuple value).\n",
      "\n",
      "You can group by more than one column as well.\n",
      "In this case, the first tuple item returned by `groupby()` will itself be a tuple with the value of each column."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for (cover, events), group_data in data.groupby([\"cloud_cover\", \"events\"]):\n",
      "    print \"Cover: {0}, Events: {1}, Count: {2}\".format(cover, events, len(group_data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Creating New Columns"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Weather events in our DataFrame are stored in strings like \"Rain-Thunderstorm\" to represent that it rained and there was a thunderstorm that day. Let's split them out into boolean \"rain\", \"thunderstorm\", etc. columns.\n",
      "\n",
      "First, let's discover the different kinds of weather events we have with `unique()`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.events.unique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks like we have \"Rain\", \"Thunderstorm\", \"Fog\", and \"Snow\" events. Creating a new column for each of these event kinds is a piece of cake with the dictionary syntax."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for event_kind in [\"Rain\", \"Thunderstorm\", \"Fog\", \"Snow\"]:\n",
      "    col_name = event_kind.lower()  # Turn \"Rain\" into \"rain\", etc.\n",
      "    data[col_name] = data.events.apply(lambda e: event_kind in e)\n",
      "data.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our new columns show up at the bottom. We can access them now with the dot syntax."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.rain"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also do cool things like find out how many `True` values there are (i.e., how many days had rain)..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.rain.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "...and get all the days that had both rain and snow!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[data.rain & data.snow].info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 6:\n",
      "\n",
      "Was the mean temperature more variable on days with rain and snow than on days with just rain or just snow?\n",
      "\n",
      "*Hint: don't forget the `std()` function*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plotting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We've already seen how the `hist()` function makes generating histograms a snap. Let's look at the `plot()` function now."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.max_temp.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That one line of code did a **lot** for us. First, it created a nice looking line plot using the maximum temperature column from our DataFrame. Second, because we used `datetime` objects in our index, pandas labeled the x-axis appropriately.\n",
      "\n",
      "Pandas is smart too. If we're only looking at a couple of days, the x-axis looks different:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.max_temp.tail().plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Prefer a bar plot? Pandas has got your covered."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.max_temp.tail().plot(kind=\"bar\", rot=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `plot()` function returns a matplotlib `AxesSubPlot` object. You can pass this object into subsequent calls to `plot()` in order to compose plots.\n",
      "\n",
      "Although `plot()` takes a variety of parameters to customize your plot, users familiar with matplotlib will feel right at home with the `AxesSubPlot` object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ax = data.max_temp.plot(title=\"Min and Max Temperatures\")\n",
      "data.min_temp.plot(style=\"red\", ax=ax)\n",
      "ax.set_ylabel(\"Temperature (F)\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 7:\n",
      "\n",
      "Add the mean temperature to the previous plot using a green line. Also, add a legend with the `legend()` method of `ax`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Getting Data Out"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Writing data out in pandas is as easy as getting data in. To save our DataFrame out to a new csv file, we can just do this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "data.to_csv(\"data/weather-mod.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Want to make that tab separated instead? No problem."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "data.to_csv(\"data/weather-mod.tsv\", sep=\"\\t\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There's also support for [reading and writing Excel files](http://pandas.pydata.org/pandas-docs/stable/io.html#excel-files), if you need it."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Reading Excel Files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The read_excel() method can read Excel 2003 (.xls) and Excel 2007 (.xlsx) files using the xlrd Python module and use the same parsing code as the above to convert tabular data into a DataFrame. See the cookbook for some advanced strategies\n",
      "\n",
      "Besides read_excel you can also read Excel files using the ExcelFile class. The following two commands are equivalent:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# using the ExcelFile class\n",
      "xls = pd.ExcelFile('path_to_file.xls')\n",
      "xls.parse('Sheet1', index_col=None, na_values=['NA'])\n",
      "\n",
      "# using the read_excel function\n",
      "read_excel('path_to_file.xls', 'Sheet1', index_col=None, na_values=['NA'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Using the sheet name:\n",
      "\n",
      "read_excel('path_to_file.xls', 'Sheet1', index_col=None, na_values=['NA'])\n",
      "Using the sheet index:\n",
      "\n",
      "read_excel('path_to_file.xls', 0, index_col=None, na_values=['NA'])\n",
      "Using all default values:\n",
      "\n",
      "read_excel('path_to_file.xls')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Miscellanea"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We've only covered a small fraction of the pandas library here.\n",
      "Before I wrap up, however, there are a few miscellaneous tips I'd like to go over.\n",
      "\n",
      "First, it can be confusing to know when an operation will modify a DataFrame and when it will return a copy to you.\n",
      "Pandas behavior here is entirely dictated by NumPy, and some situations are unintuitive.\n",
      "\n",
      "For example, what do you think will happen here?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for idx, row in data.iterrows():\n",
      "    row[\"max_temp\"] = 0\n",
      "data.max_temp.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Contrary to what you might expect, modifying `row` did **not** modify `data`!\n",
      "This is because `row` is a copy, and does not point back to the original DataFrame.\n",
      "\n",
      "Here's the right way to do it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for idx, row in data.iterrows():\n",
      "    data.max_temp.loc[idx] = 0\n",
      "any(data.max_temp != 0)  # Any rows with max_temp not equal to zero?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When using `apply()`, the default behavior is to go over columns."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.apply(lambda c: c.name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can make `apply()` go over rows by passing `axis=1`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.apply(lambda r: r[\"max_pressure\"] - r[\"min_pressure\"], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When you call `drop()`, though, it's flipped. To drop a column, you need to pass `axis=1`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.drop(\"events\", axis=1).columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Resources\n",
      "\n",
      "- [Learn Pandas](https://bitbucket.org/hrojas/learn-pandas)\n",
      "- [Compute](http://nbviewer.ipython.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/Cookbook%20-%20Compute.ipynb)\n",
      "- [Merge](http://nbviewer.ipython.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/Cookbook%20-%20Merge.ipynb)\n",
      "- [Select](http://nbviewer.ipython.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/Cookbook%20-%20Select.ipynb)\n",
      "- [Sort](http://nbviewer.ipython.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/Cookbook%20-%20Sort.ipynb)\n",
      "\n",
      "\n",
      "- [Intro to Pandas](https://bitbucket.org/hrojas/learn-pandas)\n",
      "- [Timeseries](http://nbviewer.ipython.org/github/changhiskhan/talks/blob/master/pydata2012/pandas_timeseries.ipynb)\n",
      "- [Statistics in Python](http://www.randalolson.com/2012/08/06/statistical-analysis-made-easy-in-python/)\n",
      "\n",
      "http://datacommunitydc.org/blog/2013/07/python-for-data-analysis-the-landscape-of-tutorials/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}